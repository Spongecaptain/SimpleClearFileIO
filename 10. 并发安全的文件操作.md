# 并发安全的文件操作

[toc]

## 1. Java Append to File 

在 Java 中实现 Append Only 式的文件写通过相关标志为进行控制。其有多种方式，可以参考 GitHub 项目：**[testAppendIoInJava](https://github.com/Spongecaptain/testAppendIoInJava)**。

**问题是 Append Only 式的文件写线程安全吗？**

答案是不安全，其无法确保顺序安全性。具体原因有如下几个：

- Java 线程的文件写操作虽然有先后顺序，但是由于锁位于 Writer#write 内部，因此应用层写操作的顺序在操作系统实际执行时可能出现错位；
- 操作系统仅仅能够确保单个线程的 fwrite 系统调用是线程安全的，但是并不能够确保多线程的线程安全。

这的确有点矛盾，日志的 append only 难道不就意味着顺序 I/O 吗？

为了解释这个问题，我们首先需要分清读写过程涉及的两种顺序（以写操作为例）：

1. **应用层的顺序性**：接收端先后接收到两个消息：消息A、消息B，我们要求磁盘最终落盘时，消息就是以 A、B 次序保存的；
2. **磁盘指针的顺序性**：如果有两个线程负责写入 I/O 操作，线程 1 负责写消息 B，线程 2 负责写消息 A，但如果要确保磁盘指针的顺序移动，在消息 A 必须先于消息 B 落盘的大前提下，必然要求线程 2 先写，线程 B 后写。

## 2. 为什么要为文件提供并发安全的读写能力？

要为文件提供并发安全的读写能力的原因有两点：

1. **顺序性的保障**：例如应用层先追加一个日志记录 A，后追加一个日志记录 B，需要确保文件中的存储顺序也是先 A 后 B；
2. **严格的顺序 I/O**：如果不提供多线程并发安全，顺序 I/O 也将无法保证；

## 3. 为什么顺序读写更快？

顺序读写快的原因主要有俩：

1. 顺序写比随机写更节约磁盘指针的移动总长度；
2. 顺序写最大化利用到了文件系统的缓存机制，提高了缓存命中率；

下面我们说一说原因 2 的由来：

![PageCache](./images/1364556742_9652.gif)

如上图所示，以顺序读为例，当用户发起一个 fileChannel.read(4kb) 之后，实际发生了两件事：

1. 操作系统从磁盘加载了 16kb 进入 PageCache，这被称为预读
2. 操作通从 PageCache 拷贝 4kb 进入用户内存；

最终我们在用户内存访问到了 4kb，为什么顺序读快？很容量想到，当用户继续访问接下来的 [4kb,16kb] 的磁盘内容时，便是直接从 PageCache 去访问了。试想一下，当需要访问 16kb 的磁盘内容时，是发生 4 次磁盘 I/O 快，还是发生 1 次磁盘 I/O+4 次内存 I/O 快呢？答案是显而易见的，这一切都是 PageCache 带来的优化。

深度思考：当内存吃紧时，PageCache 的分配会受影响吗？PageCache 的大小如何确定，是固定的 16kb 吗？我可以监控 PageCache 的命中情况吗？ PageCache 会在哪些场景失效，如果失效了，我们又要哪些补救方式呢？

我进行简单的自问自答，背后的逻辑还需要读者去推敲：

- 当内存吃紧时，PageCache 的预读会受到影响，实测，并没有搜到到文献支持
- PageCache 是动态调整的，可以通过 linux 的系统参数进行调整，默认是占据总内存的 20%
- https://github.com/brendangregg/perf-tools github 上一款工具可以监控 PageCache
- 如果用 PageCache 做缓存不可控，不妨自己做预读。

顺序写的原理和顺序读一致，都是收到了 PageCache 的影响，留给读者自己推敲一下。

## 4. 如何实现顺序 I/O?







## REFERENCE

- [文件 IO 操作的一些最佳实践](https://www.cnkirito.moe/file-io-best-practise/)









## REFERENCE

- \[1][]()